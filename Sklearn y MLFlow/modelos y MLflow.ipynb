{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "compound-lambda",
   "metadata": {},
   "source": [
    "# scikit-learn y MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "induced-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pretty-monday",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerFechas(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        columna_fecha = pd.to_datetime(X[\"pickup_datetime\"])\n",
    "        fecha_df = pd.DataFrame()\n",
    "        fecha_df[\"weekday\"] = columna_fecha.dt.weekday\n",
    "        fecha_df[\"hour\"] = columna_fecha.dt.hour\n",
    "        return fecha_df\n",
    "\n",
    "class TransformerDistancia(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_init = X[[\"pickup_latitude\", \"pickup_longitude\"]].to_numpy()\n",
    "        X_final = X[[\"dropoff_latitude\", \"dropoff_longitude\"]].to_numpy()\n",
    "\n",
    "        # Distancia de Haversine\n",
    "        distancia = self.distancia_haversine(X_init=X_init, X_final=X_final)\n",
    "        distancia_df = pd.DataFrame()\n",
    "        distancia_df[\"distancia\"] = distancia\n",
    "        return distancia_df\n",
    "    \n",
    "    def distancia_haversine(self, X_init, X_final):\n",
    "        # Convertir de decimal a radianes\n",
    "        X_init = np.radians(X_init)\n",
    "        X_final = np.radians(X_final)\n",
    "\n",
    "        # haversine formula \n",
    "        dlat = X_final[:, 0] - X_init[:, 0] \n",
    "        dlon = X_final[:, 1] - X_init[:, 1]\n",
    "        a = np.sin(dlat / 2) ** 2 + np.cos(X_init[:, 0]) * np.cos(X_final[:, 0]) * np.sin(dlon / 2) ** 2\n",
    "        c = 2 * np.arcsin(np.sqrt(a))\n",
    "        r = 6371 # Radius of earth in kilometers. Use 3956 for miles. Determines return value units.\n",
    "        return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "harmful-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"https://factored-workshops.s3.amazonaws.com/taxi-trip-duration.csv\")\n",
    "# Limitar rango de datos\n",
    "tiempo_minimo = 60 # 1 minuto\n",
    "tiempo_maximo = 36000 # 10 horas\n",
    "data = data[\n",
    "    (data[\"trip_duration\"] > tiempo_minimo) &\n",
    "    (data[\"trip_duration\"] < tiempo_maximo)\n",
    "]\n",
    "\n",
    "y = data[\"trip_duration\"]\n",
    "selected_columns = [\n",
    "    'vendor_id',\n",
    "    'pickup_datetime',\n",
    "    'passenger_count',\n",
    "    'pickup_longitude',\n",
    "    'pickup_latitude',\n",
    "    'dropoff_longitude',\n",
    "    'dropoff_latitude',\n",
    "    'pickup_borough',\n",
    "    'dropoff_borough'\n",
    "]\n",
    "input_df = data[selected_columns]\n",
    "train_df, val_df, y_train, y_val = train_test_split(input_df, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "worse-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pipeline.pkl\", \"rb\") as f:\n",
    "    preprocessor = dill.load(f)\n",
    "\n",
    "X_train = preprocessor.transform(train_df)\n",
    "X_val = preprocessor.transform(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-oxford",
   "metadata": {},
   "source": [
    "# Entrenar Modelos\n",
    "\n",
    "Baseline con DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cordless-hanging",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eligible-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_predicciones(y_pred, y_true):\n",
    "    mae = mean_absolute_error(y_pred=y_pred, y_true=y_true)\n",
    "    mape = mean_absolute_percentage_error(y_pred=y_pred, y_true=y_true)\n",
    "    rmse = mean_squared_error(y_pred=y_pred, y_true=y_true, squared=False)\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"MAPE: {mape}\")\n",
    "    print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "latter-circulation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "MAE: 468.61\n",
      "MAPE: 0.95585624685749\n",
      "RMSE: 683.1658889831872\n",
      "VALIDATION\n",
      "MAE: 468.42\n",
      "MAPE: 0.9567650882594899\n",
      "RMSE: 680.0030431781618\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "dummy_model = DummyRegressor(strategy=\"mean\")\n",
    "dummy_model.fit(X_train, y_train)\n",
    "y_train_dummy = dummy_model.predict(X_train)\n",
    "y_val_dummy = dummy_model.predict(X_val)\n",
    "\n",
    "print(\"TRAIN\")\n",
    "evaluar_predicciones(y_pred=y_train_dummy, y_true=y_train)\n",
    "\n",
    "print(\"VALIDATION\")\n",
    "evaluar_predicciones(y_pred=y_val_dummy, y_true=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "metric-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "legendary-jackson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "MAE: 296.09\n",
      "MAPE: 0.5533021393418197\n",
      "RMSE: 487.05043254440756\n",
      "VALIDATION\n",
      "MAE: 295.55\n",
      "MAPE: 0.554068139553269\n",
      "RMSE: 529.0958979710377\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_linear = model.predict(X_train)\n",
    "y_val_linear = model.predict(X_val)\n",
    "\n",
    "\n",
    "print(\"TRAIN\")\n",
    "evaluar_predicciones(y_pred=y_train_linear, y_true=y_train)\n",
    "\n",
    "print(\"VALIDATION\")\n",
    "evaluar_predicciones(y_pred=y_val_linear, y_true=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-envelope",
   "metadata": {},
   "source": [
    "# MLFlow ðŸ™Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "committed-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.sklearn.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eight-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"dummy\") as run:\n",
    "    dummy_model.fit(X_train, y_train)\n",
    "    y_pred_val = dummy_model.predict(X_val)\n",
    "    val_mae = mean_absolute_error(y_pred=y_pred_val, y_true=y_val)\n",
    "    val_rmse = mean_squared_error(y_pred=y_pred_val, y_true=y_val, squared=False)\n",
    "    val_mape = mean_absolute_percentage_error(y_pred=y_pred_val, y_true=y_val)\n",
    "    val_r2 = r2_score(y_pred=y_pred_val, y_true=y_val)\n",
    "\n",
    "    mlflow.log_metric(\"val_mae\", val_mae)\n",
    "    mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "    mlflow.log_metric(\"val_mape\", val_mape)\n",
    "    mlflow.log_metric(\"val_r2\", val_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "proof-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correr en terminal\n",
    "# mlflow ui "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "occupied-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"linear_regression\") as run:\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X_train, y_train)    \n",
    "    y_pred_val = linear_model.predict(X_val)\n",
    "    val_mae = mean_absolute_error(y_pred=y_pred_val, y_true=y_val)\n",
    "    val_rmse = mean_squared_error(y_pred=y_pred_val, y_true=y_val, squared=False)\n",
    "    val_mape = mean_absolute_percentage_error(y_pred=y_pred_val, y_true=y_val)\n",
    "    val_r2 = r2_score(y_pred=y_pred_val, y_true=y_val)\n",
    "\n",
    "    mlflow.log_metric(\"val_mae\", val_mae)\n",
    "    mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "    mlflow.log_metric(\"val_mape\", val_mape)\n",
    "    mlflow.log_metric(\"val_r2\", val_r2)\n",
    "    mlflow.log_artifact(\"pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weighted-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "with mlflow.start_run(run_name=\"random_forest\") as run:\n",
    "    rf_model = RandomForestRegressor(n_jobs=2)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    y_pred_val = rf_model.predict(X_val)\n",
    "    val_mae = mean_absolute_error(y_pred=y_pred_val, y_true=y_val)\n",
    "    val_rmse = mean_squared_error(y_pred=y_pred_val, y_true=y_val, squared=False)\n",
    "    val_mape = mean_absolute_percentage_error(y_pred=y_pred_val, y_true=y_val)\n",
    "    val_r2 = r2_score(y_pred=y_pred_val, y_true=y_val)\n",
    "\n",
    "    mlflow.log_metric(\"val_mae\", val_mae)\n",
    "    mlflow.log_metric(\"val_rmse\", val_rmse)\n",
    "    mlflow.log_metric(\"val_mape\", val_mape)\n",
    "    mlflow.log_metric(\"val_r2\", val_r2)\n",
    "    mlflow.log_artifact(\"pipeline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-psychology",
   "metadata": {},
   "source": [
    "## Transformer Velocidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-viking",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerVelocidad(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y):\n",
    "        X_init = X[[\"pickup_latitude\", \"pickup_longitude\"]].to_numpy()\n",
    "        X_final = X[[\"dropoff_latitude\", \"dropoff_longitude\"]].to_numpy()\n",
    "\n",
    "        # Distancia de Haversine\n",
    "        distancia = self.distancia_haversine(X_init=X_init, X_final=X_final)\n",
    "        \n",
    "        velocidad_df = pd.DataFrame()\n",
    "        tiempo_en_horas = y.to_numpy() / 3600\n",
    "        velocidad_df[\"velocidad\"] = distancia / tiempo_en_horas\n",
    "        velocidad_df[\"pickup_borough\"] = X[\"pickup_borough\"]\n",
    "        velocidad_borough = velocidad_df.groupby(\"pickup_borough\")[\"velocidad\"].mean()\n",
    "        self.velocidad_borough = velocidad_borough.to_dict()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        velocidad_df = pd.DataFrame()\n",
    "        velocidad_df[\"velocidad\"] = X[\"pickup_borough\"].map(self.velocidad_borough)\n",
    "        return velocidad_df\n",
    "    \n",
    "    def distancia_haversine(self, X_init, X_final):\n",
    "        # Convertir de decimal a radianes\n",
    "        X_init = np.radians(X_init)\n",
    "        X_final = np.radians(X_final)\n",
    "\n",
    "        # Formula de Haversine\n",
    "        dlat = X_final[:, 0] - X_init[:, 0] \n",
    "        dlon = X_final[:, 1] - X_init[:, 1]\n",
    "        a = (np.sin(dlat / 2) ** 2) + np.cos(X_init[:, 0]) * np.cos(X_final[:, 0]) * (np.sin(dlon / 2) ** 2)\n",
    "        c = 2 * np.arcsin(np.sqrt(a))\n",
    "        r = 6371 # Radio de la tierra en kilÃ³metros\n",
    "        return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_velocidades = TransformerVelocidad()\n",
    "velocidades_df = transformer_velocidades.fit_transform(train_df, y_train)\n",
    "velocidades_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-egypt",
   "metadata": {},
   "source": [
    "## Entrenando con XGBoost y LightGBM\n",
    "\n",
    "LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-amazon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "mlflow.lightgbm.autolog()\n",
    "with mlflow.start_run(run_name=\"lgbm\") as run:\n",
    "    lgbm_model = LGBMRegressor()\n",
    "    lgbm_model.fit(X_train, y_train)\n",
    "    y_pred_val = lgbm_model.predict(X_val)\n",
    "    log_metrics_mlflow(y_pred_val, y_val)\n",
    "    mlflow.log_artifact(\"preprocesser.pkl\")\n",
    "    \n",
    "    with open(\"lgbm_model.pkl\", \"wb\") as f:\n",
    "        dill.dump(lgbm_model, f)\n",
    "    mlflow.log_artifact(\"lgbm_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heard-legislation",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-mediterranean",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "mlflow.xgboost.autolog()\n",
    "with mlflow.start_run(run_name=\"xgboost\") as run:\n",
    "    xgb_model = XGBRegressor()\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred_val = xgb_model.predict(X_val)\n",
    "    log_metrics_mlflow(y_pred_val, y_val)\n",
    "    mlflow.log_artifact(\"preprocesser.pkl\")\n",
    "    \n",
    "    with open(\"xgb_model.pkl\", \"wb\") as f:\n",
    "        dill.dump(xgb_model, f)\n",
    "    mlflow.log_artifact(\"xgb_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
